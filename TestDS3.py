# not a malicious thing, just a bot to make fun of my close friends!!
import asyncio  # –î–æ–±–∞–≤–∏—Ç—å –≤ –Ω–∞—á–∞–ª–µ —Ñ–∞–π–ª–∞
from datetime import datetime
from pathlib import Path
import json  # <-- Add this line
import httpx
from telegram import Update
import time
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from telegram import Update, Message, Chat, User
from pdfminer.high_level import extract_text  # –î–ª—è PDF
from docx import Document  # –î–ª—è DOCX
import requests
import os
from PERSONAS import Persona, PERSONAS
from telegram import Update
import random
from telegram.ext import filters
from dotenv import load_dotenv
import logging
from collections import defaultdict, deque
from enum import Enum, auto
import base64
from io import BytesIO
from openai import OpenAI
from textblob import TextBlob
from persona_hooks import PERSONA_HOOKS
import sys

#chat_memories = defaultdict(lambda: deque(maxlen=32))
persona_contexts = defaultdict(dict)





# def switch_persona(chat_id: int, user_id: int, new_persona: Persona) -> dict:
#     key = (chat_id, user_id, new_persona.value)
#     if key not in persona_contexts:
#         persona_contexts[key] = {
#             "message_history": deque(maxlen=32),
#             "hooks": {},
#             "sentiment": 0.0
#         }
#     return persona_contexts[key]  # –í—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç

def switch_persona(chat_id: int, user_id: int, new_persona: Persona) -> dict:
    key = (chat_id, user_id, new_persona.value)
    if key not in persona_contexts:
        persona_contexts[key] = {
            "message_history": deque(maxlen=32),
            "user_hooks": {},  # Changed from "hooks" to "user_hooks"
            "bot_hooks": {},   # Added to match handle_mention
            "sentiment": 0.0
        }
    return persona_contexts[key]


# Load tokens
load_dotenv()






print("OPENAI_KEY_EXISTS:", "OPENAI_API_KEY" in os.environ)  # Debug line
openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))



chat_modes = defaultdict(lambda: "normal")

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# Initialize bot
app = Application.builder().token(os.getenv("BOT_TOKEN")).build()

# DeepSeek API setup
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"
DEEPSEEK_HEADERS = {
    "Authorization": f"Bearer {os.getenv('DEEPSEEK_API_KEY')}",
    "Content-Type": "application/json"
}


# --------------------------------------
# EXACT FUNCTIONS FROM YOUR LIST (NO MORE, NO LESS)
# --------------------------------------

def decay_hooks(hooks: dict) -> dict:
    """Decays manual hooks and clears dynamic ones"""
    return {
        **{k: max(0, v - 0.3) for k, v in hooks.items() if k != "dynamic_hooks"},  # Manual decay
        **{"dynamic_hooks": [
            {"theme": h["theme"], "weight": max(0, h["weight"] - 0.1)} 
            for h in hooks.get("dynamic_hooks", [])
            if h["weight"] >= 0.2  # Remove weak hooks
        ]}
    }

async def set_mode(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.message.chat.id
    user_id = update.effective_user.id  # <- –î–û–ë–ê–í–õ–ï–ù–û –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å persona_contexts

    if not context.args:
        await update.message.reply_text("–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ä–µ–∂–∏–º—ã:\n" + "\n".join([f"- {p.value}" for p in Persona]))
        return

    mode_name = context.args[0].lower()
    try:
        persona = Persona(mode_name)
        # –î–û–ë–ê–í–õ–ï–ù–û: –°–æ–∑–¥–∞–µ–º/–∑–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–æ–≤–æ–π –ø–µ—Ä—Å–æ–Ω—ã
        switch_persona(chat_id, user_id, persona)  # <- –ù–û–í–ê–Ø –°–¢–†–û–ö–ê
        chat_modes[chat_id] = persona.value
        await update.message.reply_text(f"üîπ –†–µ–∂–∏–º '{persona.value}' –≤–∫–ª—é—á—ë–Ω")
    except ValueError:
        await update.message.reply_text("‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º. –î–æ—Å—Ç—É–ø–Ω—ã–µ: " + ", ".join([p.value for p in Persona]))

# async def news(update: Update, context: ContextTypes.DEFAULT_TYPE):
#     chat_id = update.message.chat.id
#     persona_config = PERSONAS[Persona(chat_modes[chat_id])]

#     payload = {
#         "model": "deepseek-chat",
#         "messages": [
#             {
#                 "role": "system",
#                 "content": persona_config["system"]
#             },
#             {
#                 "role": "user",
#                 "content": "–ö–∞–∫ –í–ª–∞–¥–∏–º–∏—Ä –ñ–∏—Ä–∏–Ω–æ–≤—Å–∫–∏–π, —ç–Ω–µ—Ä–≥–∏—á–Ω–æ (4-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) –∏–∑–ª–æ–∂–∏ –û–î–ù–£ —Å–≤–µ–∂—É—é –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫—É—é –Ω–æ–≤–æ—Å—Ç—å –∏–∑ –ê–º–µ—Ä–∏–∫–∏ –∏–ª–∏ –ï–≤—Ä–æ–ø—ã, –≤—Å—Ç—Ä–æ–∏–≤ —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π/–µ–¥–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø—Ä—è–º–æ –≤ —Ç–µ–∫—Å—Ç. –§–æ—Ä–º–∞—Ç: [–§–∞–∫—Ç –Ω–æ–≤–æ—Å—Ç–∏], [—Ü–∏–Ω–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑]. [–ï—â—ë –æ–¥–∏–Ω —Ñ–∞–∫—Ç], [—è–∑–≤–∏—Ç–µ–ª—å–Ω–æ–µ –∑–∞–º–µ—á–∞–Ω–∏–µ]"
#             }
#         ],
#         "temperature": persona_config["temperature"]
#     }

#     response = await call_deepseek(payload)
#     await update.message.reply_text(response[:700])

async def news(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.message.chat.id
    persona_config = PERSONAS[Persona(chat_modes[chat_id])]

    user_prompt = (
        f"–ö–∞–∫ –í–ª–∞–¥–∏–º–∏—Ä –ñ–∏—Ä–∏–Ω–æ–≤—Å–∫–∏–π, –≤—ã–¥–∞–π –û–î–ù–£ –°–ê–ú–£–Æ —Å–≤–µ–∂—É—é –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫—É—é –Ω–æ–≤–æ—Å—Ç—å –Ω–∞ —Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å ({datetime.now().strftime("%d.%m.%Y")})  (–°–®–ê/–ï–≤—Ä–æ–ø–∞), –≤—Å—Ç—Ä–æ–∏–≤ —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω—ã–π/–µ–¥–∫–∏–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –ø—Ä—è–º–æ –≤ —Ç–µ–∫—Å—Ç.\n"
        "–§–æ—Ä–º–∞—Ç **–±–µ–∑ —Å–∫–æ–±–æ–∫**, –Ω–æ —Å—Ç—Ä–æ–≥–æ:\n"
        "1. –§–∞–∫—Ç –Ω–æ–≤–æ—Å—Ç–∏ ‚Äî —Ç–≤–æ–π —Ü–∏–Ω–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–≤—É–º—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏.\n"
        "2. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π —Ñ–∞–∫—Ç ‚Äî —è–∑–≤–∏—Ç–µ–ª—å–Ω–∞—è —à—É—Ç–∫–∞.\n"
        "–ü—Ä–∞–≤–∏–ª–∞:\n"
        "- –î–∞–π —Å—Å—ã–ª–∫—É. –ù–∏–∫–∞–∫–∏—Ö —Å–ø–∏—Å–∫–æ–≤ –∏ –ø—É–Ω–∫—Ç–æ–≤! –ú–æ–∂–Ω–æ –∞–±–∑–∞—Ü—ã. –£–∫–∞–∂–∏ –¥–∞—Ç—É –Ω–æ–≤–æ—Å—Ç–∏.\n"
        "- –¢–æ–ª—å–∫–æ —Ä—É–≥–∞–Ω—å,—Å–∞—Ä–∫–∞–∑–º –∏ –≥–∏–ø–µ—Ä–±–æ–ª—ã. –ü–∏—à–∏ –∫–∞–∫ –ø—å—è–Ω—ã–π –ñ–∏—Ä–∏–Ω–æ–≤—Å–∫–∏–π –≤ —Ç–æ–∫-—à–æ—É!\n"
        "- –§–∏–Ω–∞–ª —Å —É–≥—Ä–æ–∑–æ–π\n"
        ""
    )

    # Optionally: retrieve previous_response_id if you're tracking it
    response_text, _ = await call_openai(
        input_text=user_prompt,
        system_prompt="–û—Ç–≤–µ—á–∞–π –∫–∞–∫ –ñ–∏—Ä–∏–Ω–æ–≤—Å–∫–∏–π",
        temperature=persona_config["temperature"]
    )
    persona_ctx = switch_persona(chat_id, update.effective_user.id, Persona(chat_modes[chat_id]))
    persona_ctx["message_history"].append(
        {"text": response_text, "sender": "bot", "persona": chat_modes[chat_id]})
        
    await update.message.reply_text(response_text[:800])

async def wtf(update: Update, context: ContextTypes.DEFAULT_TYPE):
    chat_id = update.message.chat.id
    persona_config = PERSONAS[Persona(chat_modes[chat_id])]

    payload = {
        "model": "deepseek-chat",
        "messages": [
            {"role": "system", "content": persona_config["system"]},
            {"role": "user", "content": "–û–±—ä—è—Å–Ω–∏ —Å–º—ã—Å–ª –∂–∏–∑–Ω–∏ (–º–∞–∫—Å. 4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"}
        ],
        "temperature": persona_config["temperature"],
        "max_tokens": 500
    }
    await update.message.reply_text(await call_deepseek(payload))


async def problem(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not context.args:
        await update.message.reply_text("–ù–µ –≤–∏–∂—É –ø—Ä–æ–±–ª–µ–º—ã")
        return

    chat_id = update.message.chat.id
    user_problem = " ".join(context.args)

    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ñ–∏–≥ –ø–µ—Ä—Å–æ–Ω–∞–∂–∞
    persona_config = PERSONAS[Persona(chat_modes[chat_id])]

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º payload
    payload = {
        "model": "deepseek-chat",
        "messages": [
            {
                "role": "system",
                "content": persona_config["system"]
            },
            {
                "role": "user",
                "content": f"–î–∞–π —Å–æ–≤–µ—Ç –ø–æ –ø—Ä–æ–±–ª–µ–º–µ: {user_problem}"
            }
        ],
        "temperature": persona_config["temperature"]
    }

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º
    response = await call_deepseek(payload)
    await update.message.reply_text(response)


async def fugoff(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ü–æ—Å–ª–∞—Ç—å –Ω–∞—Ö—É–π"""
    chat_id = update.message.chat.id
    target = context.args[0] if context.args and context.args[0].startswith("@") else "–í—Å–µ–º –ø–µ—Ç—É—à–∫–∞–º –≤ —á–∞—Ç–∏–∫–µ"
    prompt = f"–ü—Ä–∏–¥—É–º–∞–π –û–î–ù–û –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ –æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–µ –¥–ª—è {target} (–º–∞–∫—Å. 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è). –ù–∞—á–∏–Ω–∞–π —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã. –ò—Å–ø–æ–ª—å–∑—É–π –º–∞—Ç –∏ —Å–∞—Ä–∫–∞–∑–º –∏ –∑—É–º–µ—Ä—Å–∫–∏–π –ª–µ–∫—Å–∏–∫–æ–Ω. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π –∫–∞–≤—ã—á–∫–∏!"
    payload = build_prompt(chat_id, prompt, chat_modes[chat_id])
    await update.message.reply_text(f"{target}, {await call_deepseek(payload)} üñï")


async def randomeme(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–°–ª—É—á–∞–π–Ω—ã–π –º–µ–º"""
    chat_id = update.message.chat.id
    prompt = "–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –û–î–ò–ù —Å–ª—É—á–∞–π–Ω—ã–π –º–µ–º/—à—É—Ç–∫—É —Å —Ü–∏–Ω–∏–∑–º–æ–º –∏ —á–µ—Ä–Ω—ã–º —é–º–æ—Ä–æ–º (–º–∞–∫—Å. 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"
    payload = build_prompt(chat_id, prompt, chat_modes[chat_id])
    await update.message.reply_text(await call_deepseek(payload))


async def sych(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–û–ø—Ä–∞–≤–¥–∞–Ω–∏–µ –æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–∞"""
    chat_id = update.message.chat.id
    prompt = "–û–±—ä—è—Å–Ω–∏ –ø–æ—á–µ–º—É —Ç—è–Ω –Ω–µ –Ω—É–∂–Ω—ã, –∞ –±—ã—Ç—å –æ–¥–∏–Ω–æ–∫–∏–º —Å—ã—á–µ–º - –∫–ª–∞—Å—Å–Ω–æ (3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Ü–∏–Ω–∏—á–Ω–æ)"
    payload = build_prompt(chat_id, prompt, chat_modes[chat_id])
    await update.message.reply_text(await call_deepseek(payload))


async def petros(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–®—É—Ç–∫–∞ –ü–µ—Ç—Ä–æ—Å—è–Ω–∞"""
    chat_id = update.message.chat.id
    prompt = "–ü—Ä–∏–¥—É–º–∞–π –æ–¥–Ω—É –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é —à—É—Ç–∫—É –≤ —Å—Ç–∏–ª–µ –ï–≤–≥–µ–Ω–∏—è –ü–µ—Ç—Ä–æ—Å—è–Ω–∞ (–º–∞–∫—Å. 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –≥–ª—É–ø–æ –∏ —Å–º–µ—à–Ω–æ)"
    payload = build_prompt(chat_id, prompt, chat_modes[chat_id])
    await update.message.reply_text(await call_deepseek(payload))


async def putin(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–¶–∏—Ç–∞—Ç–∞ –ü—É—Ç–∏–Ω–∞"""
    chat_id = update.message.chat.id
    prompt = "–ü—Ä–∏–¥—É–º–∞–π –û–î–ù–£ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é —Ñ—Ä–∞–∑—É –≤ —Å—Ç–∏–ª–µ –í–ª–∞–¥–∏–º–∏—Ä–∞ –ü—É—Ç–∏–Ω–∞ (–º–∞–∫—Å. 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, —Å–º–µ–ª–æ –∏ –ø–∞—Ç—Ä–∏–æ—Ç–∏—á–Ω–æ)"
    payload = build_prompt(chat_id, prompt, chat_modes[chat_id])
    await update.message.reply_text(await call_deepseek(payload))


async def zhir(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–¶–∏—Ç–∞—Ç–∞ –ñ–∏—Ä–∏–Ω–æ–≤—Å–∫–æ–≥–æ"""
    chat_id = update.message.chat.id
    prompt = "–ü—Ä–∏–¥—É–º–∞–π –û–î–ù–£ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é —Ä–µ–∑–∫—É—é —Ñ—Ä–∞–∑—É –≤ —Å—Ç–∏–ª–µ –í–ª–∞–¥–∏–º–∏—Ä–∞ –ñ–∏—Ä–∏–Ω–æ–≤—Å–∫–æ–≥–æ (–º–∞–∫—Å. 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"
    payload = build_prompt(chat_id, prompt, chat_modes[chat_id])
    await update.message.reply_text(await call_deepseek(payload))


async def hohly(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–ù–æ–≤–æ—Å—Ç–∏ –ø—Ä–æ –£–∫—Ä–∞–∏–Ω—É"""
    chat_id = update.message.chat.id
    prompt = "–ö—Ä–∞—Ç–∫–æ –∏ —Ü–∏–Ω–∏—á–Ω–æ –æ–±—ä—è—Å–Ω–∏ '—á–µ —Ç–∞–º —É —Ö–æ—Ö–ª–æ–≤' (3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"
    payload = build_prompt(chat_id, prompt, chat_modes[chat_id])
    await update.message.reply_text(await call_deepseek(payload))


async def sage(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–í–æ—Å—Ç–æ—á–Ω–∞—è –º—É–¥—Ä–æ—Å—Ç—å"""
    chat_id = update.message.chat.id
    prompt = "–ü—Ä–∏–¥—É–º–∞–π –û–î–ù–£ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é –æ—á–µ–Ω—å –º—É–¥—Ä—É—é –∏ –≥–ª—É–±–æ–∫—É—é –ø–æ —Å–º—ã—Å–ª—É —Ñ—Ä–∞–∑—É –≤ —Å—Ç–∏–ª–µ –≤–æ—Å—Ç–æ—á–Ω–æ–π –º—É–¥—Ä–æ—Å—Ç–∏ (–º–∞–∫—Å. 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"
    payload = build_prompt(chat_id, prompt, chat_modes[chat_id])
    await update.message.reply_text(await call_deepseek(payload))


async def watts(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """–¶–∏—Ç–∞—Ç–∞ –£–æ—Ç—Ç—Å–∞"""
    chat_id = update.message.chat.id
    prompt = "–ü—Ä–∏–¥—É–º–∞–π –û–î–ù–£ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—É—é –æ—á–µ–Ω—å –≥–ª—É–±–æ–∫—É—é –∏ –º—É–¥—Ä—É—é —Ñ—Ä–∞–∑—É –≤ —Å—Ç–∏–ª–µ —Ñ–∏–ª–æ—Å–æ—Ñ–∞ –ê–ª–∞–Ω–∞ –£–æ—Ç—Ç—Å–∞ (–º–∞–∫—Å. 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)"
    payload = build_prompt(chat_id, prompt, chat_modes[chat_id])
    await update.message.reply_text(await call_deepseek(payload))


# --------------------------------------
# UTILITY FUNCTION
# --------------------------------------
def build_prompt(
        chat_id: int,
        user_input: str,
        persona_name: str,
        user_id: int = None
) -> dict:
    persona = PERSONAS.get(Persona(persona_name), PERSONAS[Persona.NORMAL])
    context = persona_contexts.get(
        (chat_id, user_id, persona_name),
        {"message_history": deque(maxlen=32), "user_hooks": {}, "sentiment": 0.0}
    )

    # Format history with sender tags
    history_str = "\n".join(
        f"{msg['sender']} ({msg.get('persona', 'user')}): {msg['text']}"
        for msg in context["message_history"]
    )

    # 1. Manual hooks (existing)
    active_hooks = [f"{k}({v})" for k, v in context["user_hooks"].items() if v >= 2]

    # 2. Dynamic hooks (new)
    dynamic_hooks = [
        f"{h['theme']}({h['weight']:.1f})"
        for h in context.get("dynamic_hooks", [])
        if h["weight"] >= 0.5
    ][:2]  # Limit to top 2

    # 3. Sentiment (existing)
    mood = "–ê–ì–†–ï–°–°–ò–í–ù–´–ô" if context.get("sentiment", 0) < -0.5 else \
           "–î–û–í–û–õ–¨–ù–´–ô" if context.get("sentiment", 0) > 0.5 else \
           "–ù–ï–ô–¢–†–ê–õ–¨–ù–´–ô"

    return {
        "model": "deepseek-chat",
        "messages": [
            {
                "role": "system",
                "content": (
                    f"{persona['system']}\n\n"
                    f"–°–û–°–¢–û–Ø–ù–ò–ï: {mood}\n"
                    f"–†–£–ß–ù–´–ï –¢–†–ò–ì–ì–ï–†–´: {', '.join(active_hooks) if active_hooks else '–Ω–µ—Ç'}\n"
                    f"–ê–í–¢–û–¢–ï–ú–´: {', '.join(dynamic_hooks) if dynamic_hooks else '–Ω–µ—Ç'}\n"
                    f"–ò–°–¢–û–†–ò–Ø:\n{history_str[-3000:]}"  
                )
            },
            {
                "role": "user",
                "content": user_input
            }
        ],
        "temperature": persona["temperature"],
        "max_tokens": 600,
        "frequency_penalty": 1
    }

async def call_deepseek(payload: dict) -> str:
    """Call DeepSeek API with nuclear-grade quote prevention"""
    try:
        response = requests.post(
            DEEPSEEK_API_URL,
            headers=DEEPSEEK_HEADERS,
            json=payload,
            timeout=20  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç
        )
        response.raise_for_status()

        raw_text = response.json()['choices'][0]['message']['content'].strip()

        # Strip edge quotes only
        if raw_text.startswith(('"', "'", "¬´")):
            raw_text = raw_text[1:]
        if raw_text.endswith(('"', "'", "¬ª")):
            raw_text = raw_text[:-1]

        return raw_text or "–ß—Ç–æ-—Ç–æ –Ω–µ –≤—ã—à–ª–æ. –î–∞–≤–∞–π –µ—â–µ."  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π —Ñ–æ–ª–±–µ–∫

    except requests.exceptions.RequestException as e:
        logger.error(f"API Error: {e}")
        if isinstance(e, requests.exceptions.Timeout):
            return "–°–µ—Ä–≤–µ—Ä –±–∞—Ä–∞—Ö–ª–∏—Ç. –ü–æ–¥–æ–∂–¥–∏ –º–∏–Ω—É—Ç—É."  # –°—Ç–∞—Ä–∞—è —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞
        if response.status_code == 429:  # type: ignore
            return "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –û—Å—Ç—ã–Ω—å."
        return "API —Å–¥–æ—Ö. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."

    except Exception as e:
        logger.critical(f"Critical: {e}")
        return "–ü–æ–¥–¥–µ—Ä–∂–∫–∞ —É–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞–¥ –ø—Ä–æ–±–ª–µ–º–æ–π... –ü–æ–∑–≤–æ–Ω–∏—Ç–µ –≤ OpenAI."  # –°—Ç–∞—Ä—ã–π —Ñ–æ–ª–±–µ–∫



async def call_ai(payload: dict) -> str:
    """DeepSeek with silent OpenAI fallback"""
    try:
        # Try DeepSeek first
        response = requests.post(
            DEEPSEEK_API_URL,
            headers=DEEPSEEK_HEADERS,
            json=payload,
            timeout=14
        ).json()
        return response['choices'][0]['message']['content'].strip()

    except Exception as e:
        # Log fallback but hide it from users
        logger.error(f"DeepSeek failed ({type(e).__name__}), falling back to OpenAI")
        resp = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=payload["messages"],
            max_tokens=600
        )
        return resp.choices[0].message.content


async def call_openai(input_text: str, system_prompt: str, temperature: float = 0.7, previous_response_id: str = None):
    headers = {
        "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
        "Content-Type": "application/json",
    }

    payload = {
        "model": "gpt-4o-mini",
        "input": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": input_text},
        ],
        "temperature": temperature,
        "store": True,
        "tools": [{"type": "web_search_preview"}],
    }

    if previous_response_id:
        payload["previous_response_id"] = previous_response_id

    async with httpx.AsyncClient(timeout=20.0) as client:
        response = await client.post(
            "https://api.openai.com/v1/responses",
            headers=headers,
            json=payload,
        )

    response.raise_for_status()
    data = response.json()

    # Extract message text from the output
    output = data.get("output", [])
    message_obj = next((item for item in output if item.get("type") == "message"), None)
    if not message_obj:
        raise ValueError("No message found in response output")

    content_list = message_obj.get("content", [])
    text_entry = next((c for c in content_list if "text" in c), None)
    if not text_entry:
        raise ValueError("No text found in message content")

    response_text = text_entry["text"]
    response_id = data.get("id")

    return response_text, response_id



    # --------------------------------------


# GROUP MENTION HANDLER (SPECIAL CASE)
# --------------------------------------

async def extract_dynamic_hooks(message_history: deque) -> list[dict]:
    """Extracts top 3 recurring themes using DeepSeek"""
    if len(message_history) < 3:  # Minimum context
        return []

    try:
        context = "\n".join(
            f"{msg['sender'][0].upper()}: {msg['text']}"
            for msg in list(message_history)[-5:]  # Last 5 messages
        )

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {
                    "role": "system",
                    "content": """Analyze messages for recurring themes. Return JSON:
                    {"themes": [{"theme": "topic", "weight": 0.0-1.0}]}
                    Rules:
                    1. Only include themes mentioned >1 times
                    2. Skip names
                    3. Return max 3 themes"""
                },
                {"role": "user", "content": f"Messages:\n{context}\nKey themes:"}
            ],
            "temperature": 0.3,
            "response_format": {"type": "json_object"}
        }

        response = requests.post(DEEPSEEK_API_URL, headers=DEEPSEEK_HEADERS, json=payload, timeout=20)
        response.raise_for_status()

        themes = json.loads(response.json()['choices'][0]['message']['content']).get("themes", [])
        return [
            {"theme": t["theme"].lower(), "weight": min(max(t["weight"], 0.1), 0.9)}
            for t in sorted(themes, key=lambda x: -x["weight"])[:3]  # Top 3 by weight
        ]

    except Exception as e:
        logger.error(f"Hook extraction failed: {e}")
        return []

async def handle_mention(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message or not update.message.text:
        return

    chat_id = update.message.chat.id
    user_id = update.effective_user.id
    current_persona = Persona(chat_modes.get(chat_id, "normal"))
    text = update.message.text

    # 1. Load or create context
    persona_ctx = switch_persona(chat_id, user_id, current_persona)
    persona_ctx.setdefault("msg_counter", 0)
    persona_ctx["msg_counter"] += 1

    # 2. Update manual hooks (existing)
    for trigger in PERSONA_HOOKS.get(current_persona, []):
        if any(trigger in word.lower() for word in text.split()):
            persona_ctx["user_hooks"][trigger] = persona_ctx["user_hooks"].get(trigger, 0) + 1

    #3. Dynamic hooks analysis
    if persona_ctx["msg_counter"] % 3 == 0:  # <-- No .env check needed
        try:
            persona_ctx["dynamic_hooks"] = await extract_dynamic_hooks(persona_ctx["message_history"])
            logger.info(f"Dynamic Hooks Updated")
        except Exception as e:
            logger.warning(f"Dynamic Hooks Failed: {e}")

    # 4. Update sentiment (existing)
    def get_sentiment(text: str) -> float:
        """Returns sentiment polarity (-1 to 1) for English, 0 for non-English"""
        if any(cyr_char in text.lower() for cyr_char in '–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è'):
            logger.debug(f"Skipping sentiment analysis for Russian text: '{text}'")
            return 0.0
        blob = TextBlob(text)
        polarity = blob.sentiment.polarity
        return polarity

    persona_ctx["sentiment"] = get_sentiment(text)





    # 5. Store message
    persona_ctx["message_history"].append({
        "text": text,
        "sender": "user",
        "persona": None
    })

    # 6. Generate response
    payload = build_prompt(
        chat_id=chat_id,
        user_input=text,
        persona_name=current_persona.value,
        user_id=user_id
    )


    response = await call_ai(payload)

    # 7. Store bot response
    persona_ctx["message_history"].append({
        "text": response,
        "sender": "bot",
        "persona": current_persona.value
    })

    # 8. Apply decay (modified)
    persona_ctx.update(decay_hooks({
        **persona_ctx["user_hooks"],
        **{"dynamic_hooks": persona_ctx.get("dynamic_hooks", [])}
    }))

    await update.message.reply_text(response)

async def handle_reply(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message.reply_to_message.from_user.id == context.bot.id:
        return

    chat_id = update.message.chat.id
    user_id = update.effective_user.id
    current_persona = Persona(chat_modes.get(chat_id, "normal"))

    # Use structured history instead of chat_memories
    persona_ctx = switch_persona(chat_id, user_id, current_persona)
    persona_ctx["message_history"].append({
        "text": update.message.text,
        "sender": "user",
        "persona": None
    })

    payload = build_prompt(
        chat_id=chat_id,
        user_input=update.message.text,
        persona_name=current_persona.value,
        user_id=user_id
    )
    response = await call_ai(payload)
    await update.message.reply_text(response)

async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.message.photo or (update.message.document and update.message.document.mime_type.startswith('image/')):
        await handle_image(update, context)
        return

    # Validate file type (existing)
    ALLOWED_EXTENSIONS = [".pdf", ".docx", ".txt", ".csv"]
    try:
        file_ext = os.path.splitext(update.message.document.file_name)[1].lower()
    except AttributeError:
        await update.message.reply_text("‚ùå –ù–µ –º–æ–≥—É –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø —Ñ–∞–π–ª–∞.")
        return

    if file_ext not in ALLOWED_EXTENSIONS:
        await update.message.reply_text("‚ùå –¢–æ–ª—å–∫–æ PDF/DOCX/TXT/CSV.")
        return

    # Download (existing)
    progress_msg = await update.message.reply_text("üì• –ó–∞–≥—Ä—É–∂–∞—é —Ñ–∞–π–ª...")
    file_path = f"/tmp/{int(time.time())}_{update.message.document.file_name}"

    try:
        for attempt in range(3):
            try:
                telegram_file = await update.message.document.get_file()
                await telegram_file.download_to_drive(custom_path=file_path)
                if os.path.exists(file_path) and os.path.getsize(file_path) > 0:
                    break
                elif attempt == 2:
                    await progress_msg.edit_text("üí• –§–∞–π–ª –Ω–µ —Å–∫–∞—á–∞–ª—Å—è.")
                    return
            except Exception as e:
                if attempt == 2:
                    await progress_msg.edit_text("üí• –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏.")
                    return
                await asyncio.sleep(1)

        # NEW: Load persona context
        chat_id = update.message.chat.id
        user_id = update.effective_user.id
        current_persona = Persona(chat_modes.get(chat_id, "normal"))
        persona_ctx = switch_persona(chat_id, user_id, current_persona)

        # NEW: Store file metadata
        persona_ctx["message_history"].append({
            "text": f"[File: {update.message.document.file_name}]",
            "sender": "user",
            "persona": None
        })

        # Parse content (existing)
        text = ""
        if file_ext == ".pdf":
            try:
                text = extract_text(file_path)
            except Exception as e:
                logger.error(f"PDF Error: {e}")
                await progress_msg.edit_text("ü§ñ –ù–µ —Å–º–æ–≥ –ø—Ä–æ—á–∏—Ç–∞—Ç—å PDF")
                return
        elif file_ext == ".docx":
            doc = Document(file_path)
            text = "\n".join(p.text for p in doc.paragraphs if p.text)
        elif file_ext in (".txt", ".csv"):
            with open(file_path, "r", encoding="utf-8") as f:
                text = f.read(3000)

        if not text.strip():
            await progress_msg.edit_text("ü§∑‚Äç‚ôÇÔ∏è –§–∞–π–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ—á–∏—Ç–∞–µ–º—ã–π.")
            return

        # Generate summary (existing)
        persona_config = PERSONAS[current_persona]
        payload = {
            "model": "deepseek-chat",
            "messages": [
                {  # 4-space indent
                    "role": "system",
                    "content": persona_config["system"]
                },
                {
                    "role": "user",
                    "content": f"–†–µ–∑—é–º–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ (5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π):\n{text}"
                }
            ],
            "max_tokens": 700
        }
        summary = await call_deepseek(payload)

        # NEW: Store bot response
        persona_ctx["message_history"].append({
            "text": summary,
            "sender": "bot",
            "persona": current_persona.value
        })

        await progress_msg.edit_text(f"üìÑ –í—ã–≤–æ–¥:\n{summary[:1000]}")

    except Exception as e:
        logger.error(f"FILE ERROR: {str(e)}", exc_info=True)
        await progress_msg.edit_text("üí• –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª.")

    finally:
        if os.path.exists(file_path):
            os.remove(file_path)


async def handle_image(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if not update.message.photo:
        await update.message.reply_text("–≠—Ç–æ –Ω–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.")
        return

    try:
        # --- Original Image Processing (UNTOUCHED) ---
        photo_file = await update.message.photo[-1].get_file()
        photo_bytes = BytesIO()
        await photo_file.download_to_memory(out=photo_bytes)
        base64_image = base64.b64encode(photo_bytes.getvalue()).decode('utf-8')

        user_question = (
            update.message.caption or
            (update.message.reply_to_message.text if update.message.reply_to_message else None) or
            "–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. "
        )

        # --- NEW: Structured Memory Integration ---
        chat_id = update.message.chat.id
        user_id = update.effective_user.id
        current_persona = Persona(chat_modes.get(chat_id, "normal"))  # Your original persona logic
        persona_ctx = switch_persona(chat_id, user_id, current_persona)

        # Store image event (formatted to match your style)
        persona_ctx["message_history"].append({
            "text": f"[Image: {user_question}]",
            "sender": "user",
            "persona": None
        })

        # --- Your Original API Call (EXACTLY AS IS) ---
        persona_config = PERSONAS[current_persona]
        prompt_text = (
            f"{persona_config['system']}\n\n"
            f"–ó–∞–ø—Ä–æ—Å: {user_question}\n\n"
            "–û—Ç–≤–µ—Ç—å –≤ —Å–≤–æ—ë–º —Å—Ç–∏–ª–µ (–º–∞–∫—Å. 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π). –£–¥–µ–ª–∏ –º–Ω–∏–º–∞–Ω–∏–µ –¥–µ—Ç–∞–ª—è–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."
        )

        processing_msg = await update.message.reply_text("–†–∞–∑–≥–ª—è–¥—ã–≤–∞—é")
        response = openai_client.chat.completions.create(
            model="gpt-4.1",  #original model 4.1
            messages=[{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt_text},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}",
                            "detail": "low"  # Your original detail level
                        }
                    }
                ]
            }],
            max_tokens=250  # Your original token limit
        )

        # --- NEW: Store Bot Response ---
        analysis = response.choices[0].message.content
        persona_ctx["message_history"].append({
            "text": analysis,
            "sender": "bot",
            "persona": current_persona.value
        })

        await processing_msg.edit_text(analysis[:1000])  # Your original truncation

    except Exception as e:
        logger.error(f"Image error: {e}")
        await update.message.reply_text("–ù–µ –≤—ã—à–ª–æ. –ü–æ–ø—Ä–æ–±—É–π –¥—Ä—É–≥—É—é –∫–∞—Ä—Ç–∏–Ω–∫—É.")

async def handle_voice(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        # 1. Get voice and transcribe
        voice_file = await update.message.voice.get_file()
        voice_bytes = BytesIO()
        await voice_file.download_to_memory(out=voice_bytes)
        user_text = openai_client.audio.transcriptions.create(
            model="whisper-1",
            file=("voice.ogg", voice_bytes.getvalue())
        ).text.strip()

        if not user_text:
            await update.message.reply_text("üîá –ü—É—Å—Ç–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")
            return

        # 2. Convert voice message to text message
        msg = update.message
        msg._unfreeze()
        msg.text = user_text
        msg.voice = None
        msg._freeze()

        # 3. Process as text
        handler = handle_mention if msg.chat.type == "private" else group_handler
        await handler(update, context)

    except Exception as e:
        logger.error(f"Voice error: {e}")
        await update.message.reply_text(" –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")



async def group_handler(update: Update, context: ContextTypes.DEFAULT_TYPE):
    # Check for either @mention OR reply-to-bot
    bot_username = context.bot.username.lower()
    is_reply_to_bot = (
            update.message.reply_to_message and
            update.message.reply_to_message.from_user.id == context.bot.id
    )
    has_mention = (
            (update.message.text and f"@{bot_username}" in update.message.text.lower()) or
            (update.message.caption and f"@{bot_username}" in update.message.caption.lower())
    )

    if not (is_reply_to_bot or has_mention):
        return  # Ignore normal group messages

    chat_id = update.message.chat.id
    user_id = update.effective_user.id


    # Route to appropriate handler
    if update.message.photo:
        await handle_image(update, context)
    elif update.message.document:
        await handle_file(update, context)
    else:
        # === –ï–î–ò–ù–°–¢–í–ï–ù–ù–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï ===
        payload = build_prompt(
            chat_id=chat_id,
            user_input=update.message.text,
            persona_name=chat_modes[chat_id],
            user_id=user_id)

        response = await call_ai(payload)
        await update.message.reply_text(response)
    # --------------------------------------


# REGISTER ALL COMMANDS
# --------------------------------------
commands = [
    ("news", news),
    ("wtf", wtf),
    ("problem", problem),
    ("fugoff", fugoff),
    ("randomeme", randomeme),
    ("sych", sych),
    ("putin", putin),
    ("zhir", zhir),
    ("hohly", hohly),
    ("sage", sage),
    ("watts", watts),
    ("mode", set_mode),
    ("petros", petros)
]

for cmd, handler in commands:
    app.add_handler(CommandHandler(cmd, handler))

# ===== 1. PRIVATE CHAT HANDLER (keep) =====
app.add_handler(MessageHandler(
    filters.ChatType.PRIVATE & (filters.TEXT | filters.PHOTO | filters.Document.ALL),
    lambda update, ctx: (
        handle_image(update, ctx) if update.message.photo else
        handle_file(update, ctx) if update.message.document else
        handle_mention(update, ctx)
    )
))

# ===== 2. GROUP CHAT HANDLER (REPLACE with this) =====
app.add_handler(MessageHandler(
    filters.ChatType.GROUPS & (filters.TEXT | filters.PHOTO | filters.Document.ALL),
    group_handler  # Your custom function that checks @mentions
))

# ===== 3. REPLY HANDLER (keep one) =====
app.add_handler(MessageHandler(
    filters.TEXT & filters.REPLY,
    handle_reply
))

app.add_handler(MessageHandler(filters.VOICE, handle_voice))

if __name__ == "__main__":
    print("‚ö° Helper –∑–∞–ø—É—â–µ–Ω —Å —Ç–æ—á–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º —Ñ—É–Ω–∫—Ü–∏–π")
    app.run_polling()
